{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# BSc Thesis: Evaluation of Decision Tree and Random Forest Classifiers in the Finance Domain"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Chapters 0 to 3 provide functions, Chapter 4 combines these functions for convenient usage, Chapter 6 contains final evaluations\n## Table of Contents\n0. Preparation\n1. Data Preparation Stage\n2. Classification Stage\n3. Evaluation Stage\n4. Putting it all together\n5. Visualisation\n6. Final Evaluations"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# 0 | Preparation"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Imports"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Data manipulation and arrays\nimport pandas as pd\nimport numpy as np\n\n# Machine learning\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit, learning_curve, GridSearchCV, RandomizedSearchCV\nfrom sklearn import metrics\n\n# Plottig\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom IPython.display import display",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Constant variables"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Define filenames for technology stock .CSV datasets\nAAPL_DATA = \"Datasets/Kaggle_SnP500_AAPL_2013-2018.csv\"\nAMZN_DATA = \"Datasets/Kaggle_SnP500_AMZN_2013-2018.csv\"\nCSCO_DATA = \"Datasets/Kaggle_SnP500_CSCO_2013-2018.csv\"\nGE_DATA = \"Datasets/Kaggle_SnP500_GE_2013-2018.csv\"\nGOOGL_DATA = \"Datasets/Kaggle_SnP500_GOOGL_2013-2018.csv\"\nHP_DATA = \"Datasets/Kaggle_SnP500_HP_2013-2018.csv\"\nIBM_DATA = \"Datasets/Kaggle_SnP500_IBM_2013-2018.csv\"\nINTC_DATA = \"Datasets/Kaggle_SnP500_INTC_2013-2018.csv\"\nMSFT_DATA = \"Datasets/Kaggle_SnP500_MSFT_2013-2018.csv\"\nWU_DATA = \"Datasets/Kaggle_SnP500_WU_2013-2018.csv\"\nXRX_DATA = \"Datasets/Kaggle_SnP500_XRX_2013-2018.csv\"\nTECH_GROUP = [AAPL_DATA, AMZN_DATA, CSCO_DATA, GE_DATA, GOOGL_DATA, HP_DATA, IBM_DATA, INTC_DATA, MSFT_DATA, WU_DATA, XRX_DATA]\n\n# Define time horizons to compare classification results for 1-day to 1-year predictions (approx. trading days)\nTIME_HORIZONS = [1, 5, 10, 20, 65, 250]\n\n# Define verbosity\nVERBOSE = False\n\n# Centrally define if figures should be saved to ./plots/\nSAVE_FIG = False\n\n# Make code reproducible by seeding random states\nRANDOM_SEED = 42",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 1 | Data Preparation Stage\n- Load data and adjust columns as needed\n- Extract features for technical analysis\n- Define class for later classification\n- Detect anomalies in the datasets\n- No feature selection needed as embedded in Decision Trees (DT) and Random Forests (RF)\n\n## 1.1 | Load Datasets\n- For an apples-to-apples comparison, technology companies are analyzed (idea: companies/stocks within an industry have similar drivers)\n- Selected stocks differ in price trends (upward- vs constant- vs downward trend)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def load_OHLC_data(filename=MSFT_DATA, time_horizons=TIME_HORIZONS, verbose=VERBOSE, save_fig=SAVE_FIG):\n    \"\"\"\n    Loads basic stock data (date, name, open, high, low, close) from a given .CSV file and returns a corresponding DataFrame.\n    Unnecessary categorical columns are dropped, and necessary columns (e.g. month as number) are added.\n    \"\"\"\n    try:\n        df = pd.read_csv(filename)\n        \n        if save_fig is True:\n            # Visualize loaded time series data if applicable\n            df[\"date\"] = pd.to_datetime(df[\"date\"])\n            df.plot(x=\"date\", y=\"close\", figsize=(12,6), legend=None)\n            plt.xlabel(\"Time [Year]\")\n            plt.ylabel(\"Price [daily closing price in USD]\")\n            plt.title(df[\"Name\"][0] + \"-Stock Data 2013 to 2018\");\n            plt.savefig(\"./Plots/\" + df[\"Name\"][0] + \"-Stock-Price-Plot.jpeg\")\n        \n        # Calculate base column for later class: future return of stock over given time horizon (e.g. this week's Monday to next week's Monday)\n        for horizon in time_horizons:\n            df[\"return_future_\" + str(horizon) + \"d\"] = (df[\"close\"].shift(-1*horizon)/df[\"close\"])-1\n        \n        # Convert date to numerical month to possibly detect cyclicality (e.g. christmas effect) in time series\n        df[\"month\"] = df[\"date\"].astype(\"datetime64[ns]\").dt.month\n        \n        if verbose is True:\n            print(\"Loaded DataFrame has the following columns:\")\n            for col in df:\n                print(\"Column \\'\" + col + \"\\' with type\", type(df[col][0]), \", e.g.\", df[col][0])\n            print(\"df.head():\")\n            print(df.head())\n        \n        return df\n    except:\n        print(\"Error, failed to find or load OHLC data from file with name \\'\"\n              + filename + \"\\'. Please provide well-formed CSV file with OHLC stock data\")",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# df_MSFT = load_OHLC_data(MSFT_DATA)\n# df_AAPL = load_OHLC_data(AAPL_DATA)\n# df_GOOGL = load_OHLC_data(GOOGL_DATA)\n# df_HP = load_OHLC_data(HP_DATA)\n# df_IBM = load_OHLC_data(IBM_DATA)\n# df_WU = load_OHLC_data(WU_DATA)\n# df_XRX = load_OHLC_data(XRX_DATA)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.2 | Extract Features\n- Common metrics for technical analysis are calculated to be later used as features\n- TBD: Use TA libary: https://github.com/bukosabino/ta"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def extract_OHLC_features(df, time_horizons=TIME_HORIZONS):\n    \"\"\"\n    Extract common technical stock analysis features from given OHLC stock data for distinct time horizons\n    \"\"\"\n    # Calculate technical features for each time horizon\n    for horizon in time_horizons:\n#         # Future return of stock over given time horizon (e.g. this week's Monday to next week's Monday)\n#         df[\"return_future_\" + str(horizon) + \"d\"] = (df[\"close\"].shift(-1*horizon)/df[\"close\"])-1\n        \n        # Past return of stock over given time horizon (e.g. last week's Monday to this week's Monday)\n        df[\"return_past_\" + str(horizon) + \"d\"] = (df[\"close\"].shift(horizon)/df[\"close\"])-1\n        \n        # Implied volatility measured by standard deviation\n        df[\"volatility_\" + str(horizon) + \"d\"] = df[\"close\"].rolling(horizon).std()\n        \n        # Moving averages (ma)\n        df[\"ma_\" + str(horizon) + \"d\"] = df[\"close\"].rolling(horizon).mean()\n        \n#         Exponentially-weighted moving average (ewma)\n#         df[\"ewma_\" + str(horizon) + \"d\"] = pd.ewma(df[\"close\"], span=horizon, min_periods=horizon-1)\n#         df[\"ewma_\" + str(horizon) + \"d\"] = df[\"close\"].ewm(span=horizon, min_periods=horizon-1)\n        \n        # Momentum (absolute change in price over past horizon)\n        df[\"momentum_\" + str(horizon) + \"d\"] = df[\"close\"].diff(horizon)\n        \n        # Rate of change during horizon period\n        df[\"rateofchange_\" + str(horizon) + \"d\"] = (df[\"close\"].diff(horizon-1)) / (df[\"close\"].shift(horizon-1))\n        \n#         Bollinger Bands\n#         df[\"bollingerbands1_\" + str(horizon) + \"d\"] = 4*df[\"volatility_\" + str(horizon) + \"d\"] / df[\"ma_\" + str(horizon) + \"d\"]\n#         df[\"bollingerbands2_\" + str(horizon) + \"d\"] = (df[\"close\"] - df[\"ma_\" + str(horizon) + \"d\"] + 2*df[\"volatility_\" + str(horizon) + \"d\"]) / 4*df[\"volatility_\" + str(horizon) + \"d\"]\n        \n        # TBD add other talib indicators from #Pivot Points, Supports and Resistances\n    \n    # OHLC average is used for stock price average of a given day\n    df[\"ohlc_avg\"] = df[[\"open\", \"high\", \"low\", \"close\"]].mean(axis=1)\n    \n    # Replace NaNs with zeroes\n    df = df.fillna(value=0)\n    return df",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# print(\"#Features before extraction:\", len(df_MSFT.columns))\n# df_MSFT = extract_OHLC_features(df_MSFT, TIME_HORIZONS)\n# print(\"#Features after extraction:\", len(df_MSFT.columns))\n# df_AAPL = extract_OHLC_features(df_AAPL, TIME_HORIZONS)\n# df_GOOGL = extract_OHLC_features(df_GOOGL, TIME_HORIZONS)\n# df_HP = extract_OHLC_features(df_HP, TIME_HORIZONS)\n# df_IBM = extract_OHLC_features(df_IBM, TIME_HORIZONS)\n# df_WU = extract_OHLC_features(df_WU, TIME_HORIZONS)\n# df_XRX = extract_OHLC_features(df_XRX, TIME_HORIZONS)\n\n# if VERBOSE is True:\n#     print(\"With extracted features, dfMSFT.head() now yields following format:\")\n#     print(df_MSFT.head())",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 1.3 | Anomaly Detection\n- Anomaly defined as: ABS(return_past_1d) > threshold=5% (default)\n- Such anomalies (5% threshold) occur in about 1.4% of instances for seven tech stock datasets"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "def detect_anomalies(df, verbose=VERBOSE, threshold=0.05):\n    \"\"\"\n    Iterates through the DataFrame and prints out all dates where 1-day-return is greater than threshold=5% (default)\n    \"\"\"\n    if verbose is True:\n        print(\"Detecting anomalies where abs(1-day-return)>\" + str(threshold*100) + \" % for \" + df[\"Name\"][0])\n    for i in range(len(df)):\n        x = df[\"return_past_1d\"][i]\n        d = df[\"date\"][i]\n        if (abs(x) > threshold):\n            global anomaly_counter\n            anomaly_counter = anomaly_counter + 1\n            if verbose is True:\n                print(\"Anomaly: 1-day-return of \" + str(round(x * 100, 2)) + \"% on \" + d.strftime(\"%A, %d.%m.%Y\"))",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# anomaly_counter = 0\n# detect_anomalies(df_MSFT)\n# detect_anomalies(df_AAPL)\n# detect_anomalies(df_GOOGL)\n# detect_anomalies(df_HP)\n# detect_anomalies(df_IBM)\n# detect_anomalies(df_WU)\n# detect_anomalies(df_XRX)\n\n# print(\"anomaly_counter=\" + str(anomaly_counter) + \", or \" + str(round(anomaly_counter*100/(7*len(df_MSFT)), 2)) + \"% of instances\")",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.4 | Define classes\n- This notebook evaluates DT and RF for stock recommendation (application no. 2 in thesis)\n- Classes are defined for each time horizon to enable for later comparisons\n- Base columns, on which classes are built, are removed to prevent illegal future-peeking features"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def define_classes(df, time_horizons=TIME_HORIZONS):\n    \"\"\"\n    Create target column in df: 1 means 'Yes, investor should buy stock', 0 means 'No, investor should not buy stock'.\n    The assumed trading strategy here is, that the investor buy the stock on a given date and sells it after the horizon period.\n    Also removes illegal (future-peeking) columns\n    \"\"\"\n    for horizon in time_horizons:\n        base_column_name = \"return_future_\" + str(horizon) + \"d\"\n        class_name = \"class_\" + str(horizon) + \"d\"\n        \n        if class_name not in df.columns:\n            df[class_name] = np.where(df[base_column_name] > 0, 1, 0)\n        # Remove base column as it would be an illegal (future-peeking) feature\n        if base_column_name in df.columns:\n            df = df.drop(columns=[base_column_name])\n    return df",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# df_MSFT = define_classes(df_MSFT)\n# df_AAPL = define_classes(df_AAPL)\n# df_GOOGL = define_classes(df_GOOGL)\n# df_HP = define_classes(df_HP)\n# df_IBM = define_classes(df_IBM)\n# df_WU = define_classes(df_WU)\n# df_XRX = define_classes(df_XRX)\n\n# print(\"classes (class_<horizon>d) created, base columns (return_future_<horizon>d) removed\")",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.5 | Check class balance\n- The two classes Yes (1) and No (0) should be balanced, else the evaluation technique must be adapted"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def check_class_balance(df, time_horizons=TIME_HORIZONS, verbose=VERBOSE, save_fig=SAVE_FIG):\n    for horizon in time_horizons:\n        class_name = \"class_\" + str(horizon) + \"d\"\n        if verbose is True:\n            print(df[class_name].value_counts())\n\n        fig = plt.figure()\n        df[class_name].hist()\n        plt.xlabel(\"Class Value\")\n        plt.ylabel(\"Frequency\")\n        plt.title(df[\"Name\"][0] + \"-Class Value Histogram-\" + str(horizon) + \"d\")\n        if save_fig is True:\n            plt.savefig(\"./Plots/Class-Balance-Check/\" + df[\"Name\"][0] + \"-Class-Balance-Histogram-\" + str(horizon) + \"d.jpeg\")\n#         plt.close(fig) # clean memory if needed\n\n\n# check_class_balance(df_MSFT)\n# check_class_balance(df_AAPL)\n# check_class_balance(df_GOOGL)\n# check_class_balance(df_HP)\n# check_class_balance(df_IBM)\n# check_class_balance(df_WU)\n# check_class_balance(df_XRX)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##  TBD: 1.6 | Seaborn feature correlation plots\n\n- Results: TBD\n- Test old: Ergebnis: volatility-volume stark pos. korreliert (0.45), ohlc_avg-volume mäßig neg. korreliert (-0.36)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# def plot_corr_sns(df):\n#     df = df.drop(columns=[\"open\", \"high\", \"low\", \"close\", \"Name\"])\n#     corr = df.corr()\n    \n#     plt.figure()\n#     f, ax = plt.subplots(figsize=(5, 4)) #PARAM: figsize=(15, 12)\n#     ax.set_title(\"Feature Correlation Matrix\")\n#     sns.heatmap(corr, cmap=plt.cm.Blues, mask=np.zeros_like(corr, dtype=np.bool), square=True, ax=ax)\n# #     # plt.savefig(\"./plots/DataPreparation_MSFT-Stock-Data_correlation-matrix_v4.jpeg\")\n    \n# #     plt.figure()\n# #     sns.relplot(x=\"volume\", y=\"volatility_3d\", data=df);\n    \n# #     plt.figure()\n# #     sns.relplot(x=\"volume\", y=\"daily_return\", data=df);\n    \n# #     plt.figure()\n# #     sns.relplot(x=\"ohlc_avg\", y=\"ma_3\", data=df);\n\n\n# plot_corr_sns(df_MSFT)\n# # Add other df's",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# 2 | Classification Stage"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.1 | Define training and test sets\n- Seed RandomState-s uniformly to make algorithms reproducible"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def train_test_split_data(df, train_size=0.7, time_horizons=TIME_HORIZONS, verbose=VERBOSE):\n    \"\"\"\n    Generates training and testing set from a given DataFrame dataset.\n    Assumes last COUNT(time_horizons) column(s) in DataFrame are classes,\n    others are features.\n    Returns features (X) and targets (y) in training- and testing sets.\n    \"\"\"\n    # Remove non-numerical features for .fit() to work\n    df = df.drop(columns=[\"Name\", \"date\"])\n    \n    # Split DataFrame into features (X) and target (y)\n    X = df.iloc[:,:-1*len(time_horizons)]\n    y = df.iloc[:,-1*len(time_horizons):]\n    \n    # Use first (in same chronological order as time series) 70% to train and last 30% to test\n    split_index = int(len(X) * train_size)\n    if verbose is True:\n        print(\"train_test_split_data() -> Split ist bei Index \" + str(split_index) + \" von \" + str(len(X)))\n    \n    X_train, X_test = X[:split_index], X[split_index:]\n    y_train, y_test = y[:split_index], y[split_index:]\n    return X_train, X_test, y_train, y_test",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X_MSFT_train, X_MSFT_test, y_MSFT_train, y_MSFT_test = train_test_split_data(df_MSFT)\n# Add other df's\n# Better idea: just call this function later in evaluation, no extra variables needed",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.2.1 | Hyperparameter tuning for decision tree"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def tune_decision_tree(dt, X, y, verbose=VERBOSE):\n    \"\"\"\n    Returns decision tree with best hyperparameters (out of all grid combinations)\n    \"\"\"\n    # 1. Create grid with all values that should be considered as hyperparameters\n    param_grid = {\"max_depth\": [3, 5, 7, 9, 11, 13, 15, 29],\n                      \"max_features\": [3, 5, 9 ,11, 13, 15, 29],\n                      \"min_samples_split\": [3, 5, 7, 10, 15, 29],\n                      \"min_samples_leaf\": [1, 3, 5, 7, 11, 29]}\n    # 2. Run GridSearch. Randomized version is much faster with a small loss in optimality\n    tscv = TimeSeriesSplit(n_splits=10)\n    # grid_search = GridSearchCV(dt, param_grid, cv=tscv)\n    grid_search = RandomizedSearchCV(dt, param_grid, cv=tscv, random_state=RANDOM_SEED)\n    grid_search.fit(X, y)\n\n    if verbose is True:\n        print(\"tune_decision_tree() done.\")\n        print(\"Best score: \" + str(grid_search.best_score_ ))\n        print(\"Best params: \" + str(grid_search.best_params_ ))\n        print(\"Best estimator: \" + str(grid_search.best_estimator_))\n    \n    return grid_search.best_estimator_",
      "execution_count": 70,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(AAPL_DATA, horizon_index=2, train_size=1)\n# clf = DecisionTreeClassifier(random_state=RANDOM_SEED)\n# dt_new = tune_decision_tree(clf, X_train, y_train, verbose=True)\n# print(\"dt_new ist: \" + str(dt_new))",
      "execution_count": 122,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.2.2 | Hyperparameter tuning for random forest"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def tune_random_forest(rf, X, y, verbose=VERBOSE):\n    \"\"\"\n    Returns random forest with best hyperparameters (out of all grid combinations)\n    \"\"\"\n    # 1. Create grid with all values that should be considered as hyperparameters\n    param_grid = {\"max_depth\": [3, 7, 17],\n                        \"min_samples_leaf\": [3, 13, 23]}\n#     rf.set_params(n_estimators=100) # Set n_estimators afterwards to reduce searching time\n    # 2. Run GridSearch. Randomized version is much faster with a small loss in optimality\n    tscv = TimeSeriesSplit(n_splits=10)\n    # grid_search = GridSearchCV(dt, param_grid, cv=tscv)\n    grid_search = RandomizedSearchCV(rf, param_grid, cv=tscv, random_state=RANDOM_SEED, n_iter=9)\n    grid_search.fit(X, y)\n\n    if verbose is True:\n        print(\"tune_random_forest() done.\")\n        print(\"Best score: \" + str(grid_search.best_score_ ))\n        print(\"Best params: \" + str(grid_search.best_params_ ))\n        print(\"Best estimator: \" + str(grid_search.best_estimator_))\n    \n    return grid_search.best_estimator_",
      "execution_count": 142,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(AAPL_DATA, horizon_index=2, train_size=1)\n# clf = RandomForestClassifier(n_estimators=5, random_state=RANDOM_SEED)\n# rf_new = tune_random_forest(clf, X_train, y_train, verbose=True)\n# print(\"rf_new ist: \" + str(rf_new))",
      "execution_count": 144,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 3 | Evaluation Stage\n- Build confusion matrixes and calculate performance metrics \n- Plot findings"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3.1 | Evaluate classifier with Time Series CV"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def apply_tscv(clf, X, y, verbose=VERBOSE, return_raw_results=False, tuning=False):\n    \"\"\"\n    Calculates accuracy of given classifier by applying Time Series Cross Validation (tscv)\n    \"\"\"\n    # Instantiate TSCV and result variables\n    tscv = TimeSeriesSplit(n_splits=10)\n    train_sizes_manual = []\n    test_sizes_manual = []\n    train_scores_manual = []\n    test_scores_manual = []\n    y_actuals_raw = []\n    y_predicteds_raw = []\n    \n    # Manually .fit() and .evaluate() data via TSCV (as learning_curve() does not seem to work with TSCV, e.g. train_sizes wrong)\n    for train_index, test_index in tscv.split(X):\n        # 1. Define indizes for training and testing\n        first_train_index = 0\n        last_train_index = train_index[-1]\n        first_test_index = test_index[0]\n        last_test_index = test_index[-1]\n        if verbose is True:\n            print(\"Train on indices=[\" + str(first_train_index) + \", \" + str(last_train_index) + \n                  \"],test on indices=[\" + str(first_test_index) + \", \" + str(last_test_index) + \"], \" + \n                  \"i.e. train_size=\", len(train_index), \", test_size=\", len(test_index))\n        train_sizes_manual.extend([len(train_index)])\n        test_sizes_manual.extend([len(test_index)])\n        \n        # 2. Create training and test sets\n        X_train = X[first_train_index:last_train_index]\n        X_test = X[first_test_index:last_test_index]\n        y_train = y[first_train_index:last_train_index]\n        y_test = y[first_test_index:last_test_index]\n        \n        # 3. Delegate calculation of raw metrics (actuals, predicteds) or aggregated metrics (accuracy etc.)\n        if return_raw_results is True:\n            y_actual, y_predicted = calculate_metrics(clf, X_train, X_test, y_train, y_test, return_raw_results=True, tuning=tuning)\n            # 3a. Add raw values to return list\n            y_actuals_raw.extend(y_actual)\n            y_predicteds_raw.extend(y_predicted)\n        else:\n            train_score = calculate_metrics(clf, X_train, X_train, y_train, y_train, tuning=tuning)\n            test_score = calculate_metrics(clf, X_train, X_test, y_train, y_test, tuning=tuning)\n            # 3b. Add new scores to return list\n            train_scores_manual.extend([train_score])\n            test_scores_manual.extend([test_score])\n    \n    if verbose is True and return_raw_results is False:\n        print(\"train_sizes_manual=\" + str(train_sizes_manual) + \", test_sizes_manual: \" + str(test_sizes_manual))\n        print(\"train_scores_manual=\" + str([round(e, 2) for e in train_scores_manual]))\n        print(\"test_scores_manual=\" + str([round(e, 2) for e in test_scores_manual]))\n    \n    if return_raw_results is True:\n        return y_actuals_raw, y_predicteds_raw\n    else:\n        return train_sizes_manual, train_scores_manual, test_scores_manual",
      "execution_count": 79,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3.2 | Calculate metrics for given classifier's X-s and y-s"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def calculate_metrics(clf, X_train, X_test, y_train, y_test, verbose=VERBOSE, return_raw_results=False, tuning=False):\n    \"\"\"\n    Calculates accuracy, precision, recall and f-measure for given classifier for given training and test data.\n    Only accepts y-DataFrames with one single column/one single horizon (as only one class is predicted).\n    return_raw_results argument, if True, returns the raw TP/TN/FP/FN values, instead of aggregated metrics\n    \"\"\"\n    if not isinstance(y_train, pd.Series) or not isinstance(y_test, pd.Series):\n        print(\"y-DataFrames must have 1 column only.\")\n        return -1\n    \n    # 1. Tune, if applicable, and predict y-s\n    if tuning is True and isinstance(clf, type(DecisionTreeClassifier())):\n        clf = tune_decision_tree(clf, X_train, y_train)\n    elif tuning is True and isinstance(clf, type(RandomForestClassifier())):\n        clf = tune_random_forest(clf, X_train, y_train)\n        clf.set_params(n_estimators=100) # set after GridSearch to reduce searching time\n    else:\n        clf.fit(X_train, y_train)\n    y_actual = y_test\n    y_predicted = clf.predict(X_test)\n    \n    # 2. Calculate metrics\n    acc = metrics.accuracy_score(y_actual, y_predicted)\n    precision = metrics.precision_score(y_actual, y_predicted) if (1 in y_predicted and 1 in y_actual) else -1\n    recall = metrics.recall_score(y_actual, y_predicted) if (1 in y_predicted and 1 in y_actual) else -1\n    f_measure = metrics.f1_score(y_actual, y_predicted) if (precision > 0 or recall >0) else -1\n    \n    if verbose is True:\n        print(\"calculate_metrics() -> model=\" + str(type(clf)) + \", class=\" + y_train.name + \", acc=\" + str(round(acc, 2)) + \n              \"prec=\" + str(precision) + \", recall=\" + str(precision) + \", f_score=\" + str(f_measure))\n    \n    # 3. Return either raw metrics (actuals, predicteds) or aggregated metrics (accuracy etc.)\n    if return_raw_results is True:\n        return y_actual, y_predicted\n    else:\n        return acc # TBD: return other metrics as well",
      "execution_count": 132,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 4 | Putting it all together (all above methods are called here in one single place)\n- Prepare, classify and evaluate datasets"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4.1 | Summarizing function for loading & extracting vs not data & splitting for train vs test"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def generate_train_test_data(filename=MSFT_DATA, extract_features=True, horizon_index=2, train_size=0.7, verbose=VERBOSE):\n    \"\"\"\n    Serves as a one-stop-shop function for data loading incl. preparation so that classifier only relies on this single fucntion (and not many single functions) \n    \"\"\"\n    # 1. Load data from .CSV (1.1)\n    df = load_OHLC_data(filename)\n    stock_ticker = df[\"Name\"][0]\n    \n    if verbose is True:\n        print(\"generate_train_test_data() for \" + str(stock_ticker))\n    \n    # 2. Extract features if applicable (1.2)\n    if extract_features is True:\n        df = extract_OHLC_features(df)\n    \n    # Detect anomalies (1.3) skipped\n    # 3. Define classes (1.4)\n    df = define_classes(df)\n    \n    # Check class balance (1.5) skipped\n    # 4. Split data into training and testing samples if applicable (or get 100% as training data to later apply CV)\n    X_train, X_test, y_train, y_test = train_test_split_data(df, train_size=train_size)\n    \n    # 5. Return one single class series, depending on the horizon_index provided\n    y_train = y_train[y_train.columns[horizon_index]]\n    y_test = y_test[y_test.columns[horizon_index]]\n    \n    return stock_ticker, X_train, X_test, y_train, y_test",
      "execution_count": 81,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(extract_features=False)\n# print(X_train.columns)\n# print(y_train.name)\n# stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(extract_features=True)\n# print(X_train.columns)\n# print(y_train.name)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 5 | Visualization\n- Plot learning curves"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5.1 | Plot acuracy curve on train vs test data\n- E.g. for different max_depth-s of decision tree\n- Measure accuracy by TimeSeriesSplit"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def plot_tscv_curve(clf, title, X, y, verbose=VERBOSE, save_fig=SAVE_FIG):\n    \"\"\"\n    Plots the accuracies on training and testing set for given classifier using Time Series Cross Validation\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    plt.ylim(0.00, 1.05)\n    \n    # Apply Time Series CV to given data\n    train_sizes_manual, train_scores_manual, test_scores_manual = apply_tscv(clf, X, y, verbose)\n    \n    # Plot data points for training and testing\n    plt.plot(train_sizes_manual, train_scores_manual, 'o-', color=\"r\", label=\"Training\")\n    plt.plot(train_sizes_manual, test_scores_manual, 'o-', color=\"g\", label=\"Test\")\n    mean_test_acc = [np.mean(test_scores_manual)]*len(test_scores_manual)\n    plt.plot(train_sizes_manual, mean_test_acc, '--', color=\"g\", label=\"Mean\")\n    plt.text(0.5, 0.01, \"Mean=\" + str(round(np.mean(test_scores_manual), 3)), size=\"15\", weight=\"bold\", \n             horizontalalignment=\"center\", verticalalignment=\"bottom\", transform=ax.transAxes)\n    \n    # Labeling\n    plt.xlabel(\"Anzahl Trainingsinstanzen\")\n    plt.ylabel(\"Treffergenauigkeit\")\n    plt.title(title)\n    plt.grid()\n    plt.legend(loc=4)\n    \n    if save_fig is True:\n        plt.savefig(\"./Plots/Performance-Curves/Plot-\" + title.replace(\" \", \"\") + \".jpeg\")\n    \n    # Return results for plotting results in master diagram with other clf's results\n    return train_sizes_manual, train_scores_manual, test_scores_manual",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5.2 | Plot confusion matrix"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def plot_confusion_matrix(stock_ticker, horizon_index, y_actual, y_predicted, verbose=VERBOSE, save_fig=SAVE_FIG):\n    \"\"\"\n    Plots confusion matrix and returns precision, recall and f-measure\n    \"\"\"\n    # 1. Calculate metrics\n    precision = metrics.precision_score(y_actual, y_predicted) if (1 in y_predicted and 1 in y_actual) else -1\n    recall = metrics.recall_score(y_actual, y_predicted) if (1 in y_predicted and 1 in y_actual) else -1\n    f_measure = metrics.f1_score(y_actual, y_predicted) if (precision > 0 or recall >0) else -1\n    \n    if verbose is True:\n        print(\"plot_confusion_matrix() -> Result on stock=\" + str(stock_ticker) + \" is precision=\" \n              + str(round(precision, 3)) + \", recall=\" + str(round(recall, 3)) + \", f_measure=\" + str(round(f_measure, 3)))\n    if save_fig is True:\n        # 2. Build and plot confusion matrix via Seaborn\n        confusion_matrix = metrics.confusion_matrix(y_actual, y_predicted)\n        fig, ax = plt.subplots()\n        sns_ax = sns.heatmap(confusion_matrix, annot=True, annot_kws={'size':15}, fmt='g', cmap=plt.cm.Blues, cbar=False, square=True)\n        sns_ax.invert_yaxis()\n        sns_ax.invert_xaxis()\n        ax.set(title=\"Tuned RF, \" + str(stock_ticker) + \", Horizont-Index=\" + str(horizon_index), ylabel=\"Korrekte Klasse\", xlabel=\"Vorhergesagte Klasse\")\n        plt.savefig(\"./Plots/Confusion-Matrices-TunedRF/ConfusionMatrix-Tuned-RF-HorizonIndex\" + str(horizon_index) + \"-\" + str(stock_ticker) + \".jpeg\")\n        plt.close() # TBD Reinmachen wieder, nach visuellen Tests zum schnell drüberschauen\n    return precision, recall, f_measure",
      "execution_count": 134,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 6 | Final Evaluations"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 6.1 | Confusion matrixes on TSCV folds per classifier and per stock"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_tscv_confusion_matrices(clf, verbose=VERBOSE, save_fig=SAVE_FIG):\n    \"\"\"\n    Calculates confusion matrix for each stock (n=11) and for each horizon (n=6) for a total of 66 combinations\n    \"\"\"\n    # 0. Store results for averaging across datasets\n    y_act_TechGroup = [[] for h in range(0, len(TIME_HORIZONS))]\n    y_pred_TechGroup = [[] for h in range(0, len(TIME_HORIZONS))]\n    stock_ticker = None\n    \n    # 1. Load and loop over stock datasets\n    for stock in TECH_GROUP:\n        print(\"get_tscv_confusion_matrices() -> Stock=\" + str(stock))\n        # 2. Loop over prediction horizons: 1, 5, 10, 20, 65, 250 trading (!) days\n        for horizon in  range(0, len(TIME_HORIZONS)):\n            # 3. Load data for stock-horizon combination. Train_size=100% because train-test splits will be done by TSCV function\n            stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(filename=stock, extract_features=True, horizon_index=horizon, train_size=1)\n            # 2. Get TSCV predictions for confusion matrix and remember for later average across all stocks\n            y_act, y_pred = apply_tscv(clf, X_train, y_train, return_raw_results=True, tuning=True)\n            y_act_TechGroup[horizon].extend(y_act)\n            y_pred_TechGroup[horizon].extend(y_pred)\n            # 3. Create confusion matrix and save figures if applicable\n            precision, recall, f_measure = plot_confusion_matrix(stock_ticker, horizon, y_act, y_pred, verbose=True, save_fig=True)\n        \n    # 4. Average for each horizon across datasets\n    print(\"get_tscv_confusion_matrices() -> Stock=Tech Group Average\")\n    for horizon in  range(0, len(TIME_HORIZONS)):\n        precision, recall, f_measure = plot_confusion_matrix(\"Tech-Group-AVG\", horizon, y_act_TechGroup[horizon], y_pred_TechGroup[horizon], verbose=True, save_fig=True)",
      "execution_count": 146,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Throw Dummy, DT, RF into get_tscv_confusion_matrices()\n# dummy = DummyClassifier(random_state=RANDOM_SEED)\n# dt = DecisionTreeClassifier(random_state=RANDOM_SEED)\n# rf = RandomForestClassifier(n_estimators=5, random_state=RANDOM_SEED)\n# get_tscv_confusion_matrices(rf)",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": "get_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_AAPL_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.507, recall=0.37, f_measure=0.428\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.528, recall=0.441, f_measure=0.481\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.568, recall=0.427, f_measure=0.488\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.613, recall=0.449, f_measure=0.518\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.658, recall=0.486, f_measure=0.559\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.942, recall=0.84, f_measure=0.888\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_AMZN_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.532, recall=0.587, f_measure=0.558\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.563, recall=0.585, f_measure=0.574\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.529, recall=0.361, f_measure=0.429\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.586, recall=0.519, f_measure=0.55\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.741, recall=0.627, f_measure=0.679\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.889, recall=0.803, f_measure=0.844\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_CSCO_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.515, recall=0.404, f_measure=0.453\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.567, recall=0.432, f_measure=0.49\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.49, recall=0.369, f_measure=0.421\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.578, recall=0.481, f_measure=0.525\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.669, recall=0.438, f_measure=0.529\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.849, recall=0.804, f_measure=0.826\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_GE_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=GE is precision=0.474, recall=0.548, f_measure=0.508\nplot_confusion_matrix() -> Result on stock=GE is precision=0.454, recall=0.522, f_measure=0.486\nplot_confusion_matrix() -> Result on stock=GE is precision=0.47, recall=0.573, f_measure=0.517\nplot_confusion_matrix() -> Result on stock=GE is precision=0.472, recall=0.544, f_measure=0.505\nplot_confusion_matrix() -> Result on stock=GE is precision=0.562, recall=0.818, f_measure=0.666\nplot_confusion_matrix() -> Result on stock=GE is precision=0.477, recall=0.749, f_measure=0.583\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_GOOGL_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.55, recall=0.606, f_measure=0.577\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.576, recall=0.499, f_measure=0.535\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.558, recall=0.446, f_measure=0.496\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.649, recall=0.571, f_measure=0.607\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.659, recall=0.529, f_measure=0.587\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.926, recall=0.696, f_measure=0.795\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_HP_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=HP is precision=0.483, recall=0.513, f_measure=0.498\nplot_confusion_matrix() -> Result on stock=HP is precision=0.504, recall=0.625, f_measure=0.558\nplot_confusion_matrix() -> Result on stock=HP is precision=0.505, recall=0.578, f_measure=0.539\nplot_confusion_matrix() -> Result on stock=HP is precision=0.45, recall=0.588, f_measure=0.51\nplot_confusion_matrix() -> Result on stock=HP is precision=0.513, recall=0.791, f_measure=0.622\nplot_confusion_matrix() -> Result on stock=HP is precision=0.353, recall=0.702, f_measure=0.47\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_IBM_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.504, recall=0.519, f_measure=0.512\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.468, recall=0.493, f_measure=0.48\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.459, recall=0.369, f_measure=0.409\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.445, recall=0.312, f_measure=0.367\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.547, recall=0.584, f_measure=0.565\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.581, recall=0.583, f_measure=0.582\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_INTC_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.525, recall=0.579, f_measure=0.551\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.565, recall=0.637, f_measure=0.599\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.592, recall=0.472, f_measure=0.525\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.615, recall=0.576, f_measure=0.595\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.65, recall=0.572, f_measure=0.608\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.721, recall=0.783, f_measure=0.751\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_MSFT_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.53, recall=0.406, f_measure=0.46\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.64, recall=0.554, f_measure=0.594\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.668, recall=0.428, f_measure=0.522\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.792, recall=0.473, f_measure=0.593\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.835, recall=0.678, f_measure=0.749\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.95, recall=0.994, f_measure=0.972\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_WU_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=WU is precision=0.505, recall=0.55, f_measure=0.527\nplot_confusion_matrix() -> Result on stock=WU is precision=0.511, recall=0.601, f_measure=0.552\nplot_confusion_matrix() -> Result on stock=WU is precision=0.481, recall=0.508, f_measure=0.494\nplot_confusion_matrix() -> Result on stock=WU is precision=0.468, recall=0.535, f_measure=0.5\nplot_confusion_matrix() -> Result on stock=WU is precision=0.458, recall=0.404, f_measure=0.429\nplot_confusion_matrix() -> Result on stock=WU is precision=0.572, recall=0.725, f_measure=0.639\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_XRX_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.497, recall=0.634, f_measure=0.557\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.552, recall=0.781, f_measure=0.647\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.547, recall=0.856, f_measure=0.668\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.548, recall=0.752, f_measure=0.634\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.465, recall=0.727, f_measure=0.567\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.309, recall=0.854, f_measure=0.454\nget_tscv_confusion_matrices() -> Stock=Tech Group Average\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.511, recall=0.52, f_measure=0.515\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.538, recall=0.561, f_measure=0.549\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.531, recall=0.486, f_measure=0.508\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.56, recall=0.528, f_measure=0.543\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.611, recall=0.595, f_measure=0.603\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.702, recall=0.795, f_measure=0.745\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# NExxt Steps: \n- Hyperparam Tuning einbauen DONE\n- Feature Improtances messen\n- Fazit ziehen"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# --------------------------------------------Ignore below------------------------------------------------"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4.3 | Test master function\n- Varying 4-5 dimensions simultaneously too complex, hence all but classifier is fixed in the master function\n- TBD: Toggle Hyperparameter Tuning somewhere\n- TBD: Correct testing for 0 values at the end, e.g. 365 horizon return in last week's data is always 0!! Must be accounted for"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# TIME_HORIZONS = [1, 5, 10, 20, 65, 250] <- use index from 0 (1 trading day) to 5 (250 trading days) to determine time horizon\ndef master_function(time_horizon=2):\n    # Create classifiers that are to be evaluated\n    clf1 = DummyClassifier(random_state=42)\n    clf2 = DecisionTreeClassifier(random_state=42)\n    clf3 = RandomForestClassifier(n_estimators=10, random_state=42)\n    clfs = [clf1, clf2, clf3]\n    \n    # Iterate over models & datasets to evaluate classifiers on each dataset\n    for clf in clfs:\n        cum_acc = 0\n        for dataset_path in TECH_GROUP:\n            # Load data and evaluate all models on it\n            evaluate_models(dataset=dataset_path, extract_features=False, time_horizon=time_horizon)\n            cum_acc = cum_acc + evaluate_models(dataset=dataset_path, extract_features=True, time_horizon=time_horizon)\n        clf_avg_acc = cum_acc/len(TECH_GROUP)\n        print(\"avg acc for \" + str(type(clf)) + \" is \" + str(round(clf_avg_acc, 2)))",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# master_function()",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.1.1 | Decision tree hyperparameter variation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def evaluate_dt(filename=AAPL_DATA, extract_features=True, horizon_index=2):\n    # Load data\n    stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(filename, extract_features, horizon_index, train_size=1)\n\n    # Generate classifier\n    clf = DecisionTreeClassifier(random_state=RANDOM_SEED)\n\n    # Gather all plotted series to create master plot\n    plotted_Xs = []\n    plotted_ys_train = []\n    plotted_ys_test = []\n\n    # Evaluate classifier for different values of selected hyperparameter\n    for i in [1, 3, 5, 6, 7, 9, 11, None]:\n        clf.set_params(max_depth=i)\n        X_res, y_train_res, y_test_res = plot_tscv_curve(clf, \"Decision Tree Treffergenauigkeiten AAPL (MAX_DEPTH=\" + str(i) + \")\", X_train, y_train, save_fig=SAVE_FIG)\n        print(\"Mean test accuracy for MAX_DEPTH=\" + str(i) + \": \" + str(round(np.mean(y_test_res), 3)))\n        \n        # Throw best params from 2.2 (Hyperparameter tuning) in and see if same result\n        if i == 7:\n            print(\"i is 7, so here we try the GRID_SEARCHED-best params: 'max_depth': 29, 'max_features': 29, 'min_samples_leaf': 1, 'min_samples_split': 15}, achieved 58.3% acc above\")\n            clf_best_params = DecisionTreeClassifier(random_state=RANDOM_SEED, max_depth=29, max_features=29, min_samples_leaf=1, min_samples_split=15)\n            X_res, y_train_res, y_test_res = plot_tscv_curve(clf_best_params, \"Decision Tree Treffergenauigkeiten AAPL (BEST_PARAMS)\", X_train, y_train, save_fig=SAVE_FIG)\n            print(\"Best-params DT achievend ACC=\" + str(i) + \": \" + str(round(np.mean(y_test_res), 3)))\n        \n        # TBD: Use all results to make master plot\n        plotted_Xs.extend([X_res])\n        plotted_ys_train.extend([y_train_res])\n        plotted_ys_test.extend([y_test_res])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# evaluate_dt(filename=AAPL_DATA, extract_features=True, horizon_index=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.1.2 | Classifier horizon variation (averaged aross TECH_GROUP)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def eval_avg_across_tech(clf):\n    \"\"\"\n    Evaluates accuracy of given classifier for each time horizon (accuracy average cross TECH_GROUP)\n    \"\"\"\n    accs_horizons = []\n    for horizon in range(0, 6):\n        accs_datasets = []\n        for file in TECH_GROUP:\n            # 1. Load data\n            stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(file, horizon_index=horizon, train_size=1)\n            \n            # 2. Evaluate classifier\n            train_sizes_manual, train_scores_manual, test_scores_manual = apply_tscv(clf, X_train, y_train)\n#             print(\"ACC for horizon=\" + str(horizon) + \" & file=\" + str(file) + \" is \" + str(np.mean(test_scores_manual)))\n            accs_datasets.extend([np.mean(test_scores_manual)])\n        print(\"ACC for horizon=\" + str(horizon) + \" is \" + str(np.mean(accs_datasets)))\n        accs_horizons.extend([np.mean(accs_datasets)])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# clf = DecisionTreeClassifier(random_state=RANDOM_SEED)\n# eval_avg_across_tech(clf)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# clf = RandomForestClassifier(random_state=RANDOM_SEED)\n# eval_avg_across_tech(clf)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.2 | Random forest hyperparameter variation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def evaluate_rf(filename=AAPL_DATA, extract_features=True, horizon_index=2):\n    # Load data\n    stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(filename, extract_features, horizon_index, train_size=1)\n\n    # Generate classifier\n    clf = RandomForestClassifier(n_estimators = 1, random_state=RANDOM_SEED)\n\n    # Evaluate classifier for different values of selected hyperparameter\n    for i in [1, 5, 10, 50, 100]:\n        clf.set_params(n_estimators=i)\n        X_res, y_train_res, y_test_res = plot_tscv_curve(clf, \"Random Forest Treffergenauigkeiten AAPL (N_ESTIMATORS=\" + str(i) + \")\", X_train, y_train, save_fig=SAVE_FIG)\n        print(\"Mean test accuracy for N_ESTIMATORS=\" + str(i) + \": \" + str(round(np.mean(y_test_res), 3)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# evaluate_rf(filename=MSFT_DATA, extract_features=True, horizon_index=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Comparison table: Model-Extractets-Horizon"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "- DT auf AAPL: Bei Variierung von MAX_DEPTH ist MAX(EXTRACTEDS)=56.2 , MAX(NO EXTRACTEDS)=53.3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}