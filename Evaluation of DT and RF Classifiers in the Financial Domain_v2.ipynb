{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# BSc Thesis: Evaluation of Decision Tree and Random Forest Classifiers in the Finance Domain"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Chapters 0 to 3 provide functions, Chapter 4 combines these functions for convenient usage, Chapter 6 contains final evaluations\n## Table of Contents\n0. Preparation\n1. Data Preparation Stage\n2. Classification Stage\n3. Evaluation Stage\n4. Putting it all together\n5. Visualisation\n6. Final Evaluations"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# 0 | Preparation"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Imports"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Data manipulation and arrays\nimport pandas as pd\nimport numpy as np\n\n# Machine learning\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit, learning_curve, GridSearchCV, RandomizedSearchCV\nfrom sklearn import metrics\n\n# Plottig\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom IPython.display import display",
      "execution_count": 100,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Constant variables"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Define filenames for technology stock .CSV datasets\nAAPL_DATA = \"Datasets/Kaggle_SnP500_AAPL_2013-2018.csv\"\nAMZN_DATA = \"Datasets/Kaggle_SnP500_AMZN_2013-2018.csv\"\nCSCO_DATA = \"Datasets/Kaggle_SnP500_CSCO_2013-2018.csv\"\nGE_DATA = \"Datasets/Kaggle_SnP500_GE_2013-2018.csv\"\nGOOGL_DATA = \"Datasets/Kaggle_SnP500_GOOGL_2013-2018.csv\"\nHP_DATA = \"Datasets/Kaggle_SnP500_HP_2013-2018.csv\"\nIBM_DATA = \"Datasets/Kaggle_SnP500_IBM_2013-2018.csv\"\nINTC_DATA = \"Datasets/Kaggle_SnP500_INTC_2013-2018.csv\"\nMSFT_DATA = \"Datasets/Kaggle_SnP500_MSFT_2013-2018.csv\"\nWU_DATA = \"Datasets/Kaggle_SnP500_WU_2013-2018.csv\"\nXRX_DATA = \"Datasets/Kaggle_SnP500_XRX_2013-2018.csv\"\nTECH_GROUP = [AAPL_DATA, AMZN_DATA, CSCO_DATA, GE_DATA, GOOGL_DATA, HP_DATA, IBM_DATA, INTC_DATA, MSFT_DATA, WU_DATA, XRX_DATA]\n\n# Define time horizons to compare classification results for 1-day to 1-year predictions (approx. trading days)\nTIME_HORIZONS = [1, 5, 10, 20, 65, 250]\n\n# Define verbosity\nVERBOSE = False\n\n# Centrally define if figures should be saved to ./plots/\nSAVE_FIG = False\n\n# Make code reproducible by seeding random states\nRANDOM_SEED = 42",
      "execution_count": 101,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 1 | Data Preparation Stage\n- Load data and adjust columns as needed\n- Extract features for technical analysis\n- Define class for later classification\n- Detect anomalies in the datasets\n- No feature selection needed as embedded in Decision Trees (DT) and Random Forests (RF)\n\n## 1.1 | Load Datasets\n- For an apples-to-apples comparison, technology companies are analyzed (idea: companies/stocks within an industry have similar drivers)\n- Selected stocks differ in price trends (upward- vs constant- vs downward trend)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def load_OHLC_data(filename=MSFT_DATA, time_horizons=TIME_HORIZONS, verbose=VERBOSE, save_fig=SAVE_FIG):\n    \"\"\"\n    Loads basic stock data (date, name, open, high, low, close) from a given .CSV file and returns a corresponding DataFrame.\n    Unnecessary categorical columns are dropped, and necessary columns (e.g. month as number) are added.\n    \"\"\"\n    try:\n        df = pd.read_csv(filename)\n        \n        if save_fig is True:\n            # Visualize loaded time series data if applicable\n            df[\"date\"] = pd.to_datetime(df[\"date\"])\n            df.plot(x=\"date\", y=\"close\", figsize=(12,6), legend=None)\n            plt.xlabel(\"Time [Year]\")\n            plt.ylabel(\"Price [daily closing price in USD]\")\n            plt.title(df[\"Name\"][0] + \"-Stock Data 2013 to 2018\");\n            plt.savefig(\"./Plots/\" + df[\"Name\"][0] + \"-Stock-Price-Plot.jpeg\")\n        \n        # Calculate base column for later class: future return of stock over given time horizon (e.g. this week's Monday to next week's Monday)\n        for horizon in time_horizons:\n            df[\"return_future_\" + str(horizon) + \"d\"] = (df[\"close\"].shift(-1*horizon)/df[\"close\"])-1\n        \n        # Convert date to numerical month to possibly detect cyclicality (e.g. christmas effect) in time series\n        df[\"month\"] = df[\"date\"].astype(\"datetime64[ns]\").dt.month\n        \n        if verbose is True:\n            print(\"Loaded DataFrame has the following columns:\")\n            for col in df:\n                print(\"Column \\'\" + col + \"\\' with type\", type(df[col][0]), \", e.g.\", df[col][0])\n            print(\"df.head():\")\n            print(df.head())\n        \n        return df\n    except:\n        print(\"Error, failed to find or load OHLC data from file with name \\'\"\n              + filename + \"\\'. Please provide well-formed CSV file with OHLC stock data\")",
      "execution_count": 102,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# df_MSFT = load_OHLC_data(MSFT_DATA)\n# df_AAPL = load_OHLC_data(AAPL_DATA)\n# df_GOOGL = load_OHLC_data(GOOGL_DATA)\n# df_HP = load_OHLC_data(HP_DATA)\n# df_IBM = load_OHLC_data(IBM_DATA)\n# df_WU = load_OHLC_data(WU_DATA)\n# df_XRX = load_OHLC_data(XRX_DATA)",
      "execution_count": 103,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.2 | Extract Features\n- Common metrics for technical analysis are calculated to be later used as features\n- TBD: Use TA libary: https://github.com/bukosabino/ta"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def extract_OHLC_features(df, time_horizons=TIME_HORIZONS):\n    \"\"\"\n    Extract common technical stock analysis features from given OHLC stock data for distinct time horizons\n    \"\"\"\n    # Calculate technical features for each time horizon\n    for horizon in time_horizons:\n#         # Future return of stock over given time horizon (e.g. this week's Monday to next week's Monday)\n#         df[\"return_future_\" + str(horizon) + \"d\"] = (df[\"close\"].shift(-1*horizon)/df[\"close\"])-1\n        \n        # Past return of stock over given time horizon (e.g. last week's Monday to this week's Monday)\n        df[\"return_past_\" + str(horizon) + \"d\"] = (df[\"close\"].shift(horizon)/df[\"close\"])-1\n        \n        # Implied volatility measured by standard deviation\n        df[\"volatility_\" + str(horizon) + \"d\"] = df[\"close\"].rolling(horizon).std()\n        \n        # Moving averages (ma)\n        df[\"ma_\" + str(horizon) + \"d\"] = df[\"close\"].rolling(horizon).mean()\n        \n#         Exponentially-weighted moving average (ewma)\n#         df[\"ewma_\" + str(horizon) + \"d\"] = pd.ewma(df[\"close\"], span=horizon, min_periods=horizon-1)\n#         df[\"ewma_\" + str(horizon) + \"d\"] = df[\"close\"].ewm(span=horizon, min_periods=horizon-1)\n        \n        # Momentum (absolute change in price over past horizon)\n        df[\"momentum_\" + str(horizon) + \"d\"] = df[\"close\"].diff(horizon)\n        \n        # Rate of change during horizon period\n        df[\"rateofchange_\" + str(horizon) + \"d\"] = (df[\"close\"].diff(horizon-1)) / (df[\"close\"].shift(horizon-1))\n        \n#         Bollinger Bands\n#         df[\"bollingerbands1_\" + str(horizon) + \"d\"] = 4*df[\"volatility_\" + str(horizon) + \"d\"] / df[\"ma_\" + str(horizon) + \"d\"]\n#         df[\"bollingerbands2_\" + str(horizon) + \"d\"] = (df[\"close\"] - df[\"ma_\" + str(horizon) + \"d\"] + 2*df[\"volatility_\" + str(horizon) + \"d\"]) / 4*df[\"volatility_\" + str(horizon) + \"d\"]\n        \n        # TBD add other talib indicators from #Pivot Points, Supports and Resistances\n    \n    # OHLC average is used for stock price average of a given day\n    df[\"ohlc_avg\"] = df[[\"open\", \"high\", \"low\", \"close\"]].mean(axis=1)\n    \n    # Replace NaNs with zeroes\n    df = df.fillna(value=0)\n    return df",
      "execution_count": 104,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# print(\"#Features before extraction:\", len(df_MSFT.columns))\n# df_MSFT = extract_OHLC_features(df_MSFT, TIME_HORIZONS)\n# print(\"#Features after extraction:\", len(df_MSFT.columns))\n# df_AAPL = extract_OHLC_features(df_AAPL, TIME_HORIZONS)\n# df_GOOGL = extract_OHLC_features(df_GOOGL, TIME_HORIZONS)\n# df_HP = extract_OHLC_features(df_HP, TIME_HORIZONS)\n# df_IBM = extract_OHLC_features(df_IBM, TIME_HORIZONS)\n# df_WU = extract_OHLC_features(df_WU, TIME_HORIZONS)\n# df_XRX = extract_OHLC_features(df_XRX, TIME_HORIZONS)\n\n# if VERBOSE is True:\n#     print(\"With extracted features, dfMSFT.head() now yields following format:\")\n#     print(df_MSFT.head())",
      "execution_count": 105,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 1.3 | Anomaly Detection\n- Anomaly defined as: ABS(return_past_1d) > threshold=5% (default)\n- Such anomalies (5% threshold) occur in about 1.4% of instances for seven tech stock datasets"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "def detect_anomalies(df, verbose=VERBOSE, threshold=0.05):\n    \"\"\"\n    Iterates through the DataFrame and prints out all dates where 1-day-return is greater than threshold=5% (default)\n    \"\"\"\n    if verbose is True:\n        print(\"Detecting anomalies where abs(1-day-return)>\" + str(threshold*100) + \" % for \" + df[\"Name\"][0])\n    for i in range(len(df)):\n        x = df[\"return_past_1d\"][i]\n        d = df[\"date\"][i]\n        if (abs(x) > threshold):\n            global anomaly_counter\n            anomaly_counter = anomaly_counter + 1\n            if verbose is True:\n                print(\"Anomaly: 1-day-return of \" + str(round(x * 100, 2)) + \"% on \" + d.strftime(\"%A, %d.%m.%Y\"))",
      "execution_count": 106,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# anomaly_counter = 0\n# detect_anomalies(df_MSFT)\n# detect_anomalies(df_AAPL)\n# detect_anomalies(df_GOOGL)\n# detect_anomalies(df_HP)\n# detect_anomalies(df_IBM)\n# detect_anomalies(df_WU)\n# detect_anomalies(df_XRX)\n\n# print(\"anomaly_counter=\" + str(anomaly_counter) + \", or \" + str(round(anomaly_counter*100/(7*len(df_MSFT)), 2)) + \"% of instances\")",
      "execution_count": 107,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.4 | Define classes\n- This notebook evaluates DT and RF for stock recommendation (application no. 2 in thesis)\n- Classes are defined for each time horizon to enable for later comparisons\n- Base columns, on which classes are built, are removed to prevent illegal future-peeking features"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def define_classes(df, time_horizons=TIME_HORIZONS):\n    \"\"\"\n    Create target column in df: 1 means 'Yes, investor should buy stock', 0 means 'No, investor should not buy stock'.\n    The assumed trading strategy here is, that the investor buy the stock on a given date and sells it after the horizon period.\n    Also removes illegal (future-peeking) columns\n    \"\"\"\n    for horizon in time_horizons:\n        base_column_name = \"return_future_\" + str(horizon) + \"d\"\n        class_name = \"class_\" + str(horizon) + \"d\"\n        \n        if class_name not in df.columns:\n            df[class_name] = np.where(df[base_column_name] > 0, 1, 0)\n        # Remove base column as it would be an illegal (future-peeking) feature\n        if base_column_name in df.columns:\n            df = df.drop(columns=[base_column_name])\n    return df",
      "execution_count": 108,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# df_MSFT = define_classes(df_MSFT)\n# df_AAPL = define_classes(df_AAPL)\n# df_GOOGL = define_classes(df_GOOGL)\n# df_HP = define_classes(df_HP)\n# df_IBM = define_classes(df_IBM)\n# df_WU = define_classes(df_WU)\n# df_XRX = define_classes(df_XRX)\n\n# print(\"classes (class_<horizon>d) created, base columns (return_future_<horizon>d) removed\")",
      "execution_count": 109,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.5 | Check class balance\n- The two classes Yes (1) and No (0) should be balanced, else the evaluation technique must be adapted"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def check_class_balance(df, time_horizons=TIME_HORIZONS, verbose=VERBOSE, save_fig=SAVE_FIG):\n    for horizon in time_horizons:\n        class_name = \"class_\" + str(horizon) + \"d\"\n        if verbose is True:\n            print(df[class_name].value_counts())\n\n        fig = plt.figure()\n        df[class_name].hist()\n        plt.xlabel(\"Class Value\")\n        plt.ylabel(\"Frequency\")\n        plt.title(df[\"Name\"][0] + \"-Class Value Histogram-\" + str(horizon) + \"d\")\n        if save_fig is True:\n            plt.savefig(\"./Plots/Class-Balance-Check/\" + df[\"Name\"][0] + \"-Class-Balance-Histogram-\" + str(horizon) + \"d.jpeg\")\n#         plt.close(fig) # clean memory if needed\n\n\n# check_class_balance(df_MSFT)\n# check_class_balance(df_AAPL)\n# check_class_balance(df_GOOGL)\n# check_class_balance(df_HP)\n# check_class_balance(df_IBM)\n# check_class_balance(df_WU)\n# check_class_balance(df_XRX)",
      "execution_count": 110,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##  TBD: 1.6 | Seaborn feature correlation plots\n\n- Results: TBD\n- Test old: Ergebnis: volatility-volume stark pos. korreliert (0.45), ohlc_avg-volume mäßig neg. korreliert (-0.36)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# def plot_corr_sns(df):\n#     df = df.drop(columns=[\"open\", \"high\", \"low\", \"close\", \"Name\"])\n#     corr = df.corr()\n    \n#     plt.figure()\n#     f, ax = plt.subplots(figsize=(5, 4)) #PARAM: figsize=(15, 12)\n#     ax.set_title(\"Feature Correlation Matrix\")\n#     sns.heatmap(corr, cmap=plt.cm.Blues, mask=np.zeros_like(corr, dtype=np.bool), square=True, ax=ax)\n# #     # plt.savefig(\"./plots/DataPreparation_MSFT-Stock-Data_correlation-matrix_v4.jpeg\")\n    \n# #     plt.figure()\n# #     sns.relplot(x=\"volume\", y=\"volatility_3d\", data=df);\n    \n# #     plt.figure()\n# #     sns.relplot(x=\"volume\", y=\"daily_return\", data=df);\n    \n# #     plt.figure()\n# #     sns.relplot(x=\"ohlc_avg\", y=\"ma_3\", data=df);\n\n\n# plot_corr_sns(df_MSFT)\n# # Add other df's",
      "execution_count": 111,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# 2 | Classification Stage\n- Apply classifiers on datasets (for each time horizon-company combination)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.1 | Define training and test sets\n- Seed RandomState to make algorithms reproducible"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def train_test_split_data(df, train_size=0.7, time_horizons=TIME_HORIZONS, verbose=VERBOSE):\n    \"\"\"\n    Generates training and testing set from a given DataFrame dataset.\n    Assumes last COUNT(time_horizons) column(s) in DataFrame are classes,\n    others are features.\n    Returns features (X) and targets (y) in training- and testing sets.\n    \"\"\"\n    # Remove non-numerical features for .fit() to work\n    df = df.drop(columns=[\"Name\", \"date\"])\n    \n    # Split DataFrame into features (X) and target (y)\n    X = df.iloc[:,:-1*len(time_horizons)]\n    y = df.iloc[:,-1*len(time_horizons):]\n    \n    # Use first (in same chronological order as time series) 70% to train and last 30% to test\n    split_index = int(len(X) * train_size)\n    if verbose is True:\n        print(\"train_test_split_data() -> Split ist bei Index \" + str(split_index) + \" von \" + str(len(X)))\n    \n    X_train, X_test = X[:split_index], X[split_index:]\n    y_train, y_test = y[:split_index], y[split_index:]\n    return X_train, X_test, y_train, y_test",
      "execution_count": 112,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X_MSFT_train, X_MSFT_test, y_MSFT_train, y_MSFT_test = train_test_split_data(df_MSFT)\n# Add other df's\n# Better idea: just call this function later in evaluation, no extra variables needed",
      "execution_count": 113,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.2.1 | Hyperparameter tuning DT"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def tune_hp_dt(dt, X, y, verbose=VERBOSE):\n    param_grid = {\"max_depth\": [3, 5, 7, 9, 11, 13, 15, 29],\n                      \"max_features\": [3, 5, 10, 15, 29],\n                      \"min_samples_split\": [3, 5, 7, 10, 15, 29],\n                      \"min_samples_leaf\": [1, 3, 5, 7, 11, 29]}\n#     param_grid_fast = {\"max_depth\": [3, 5, 29],\n#                       \"max_features\": [3, 29],\n#                       \"min_samples_split\": [3, 29],\n#                       \"min_samples_leaf\": [1, 5]}\n    # Use time series CV instead of \n#     grid_search = GridSearchCV(dt, param_grid)\n    tscv = TimeSeriesSplit(n_splits=10)\n    grid_search = GridSearchCV(dt, param_grid, cv=tscv)\n    grid_search.fit(X, y)\n    \n    if verbose is True:\n        print(\"tune_hp_dt() done.\")\n        print(\"Best score: \" + str(grid_search.best_score_ ))\n        print(\"Best params: \" + str(grid_search.best_params_ ))\n        print(\"Best estimator: \" + str(grid_search.best_estimator_))\n        # print(str(grid_search.cv_results_))\n    \n    return grid_search.best_estimator_",
      "execution_count": 114,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(AAPL_DATA, train_size=1)\n# clf = DecisionTreeClassifier(random_state=RANDOM_SEED)\n# tune_hp_dt(clf, X_train, y_train)",
      "execution_count": 115,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2.2.2 | Hyperparameter tuning RF"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Generic gridsearch function\ndef tune_hp_rf(rf, criteria):\n    param_grid = {\"max_depth\": [3, 5, 7, 9, 11, 13, 15, None],\n                      \"max_features\": [3, 5, 10, 15, None],\n                      \"min_samples_split\": [3, 5, 7, 10, 15, None],\n                      \"bootstrap\": [True, False]}\n    GridSearchCV(rf, param_grid)",
      "execution_count": 116,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 3 | Evaluation Stage\n- Build confusion matrixes and calculate performance metrics \n- Plot findings"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3.1 | Evaluate classifier with Time Series CV"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def apply_tscv(clf, X, y, verbose=VERBOSE, return_raw_results=False):\n    \"\"\"\n    Calculates accuracy of given classifier by applying Time Series Cross Validation (tscv)\n    \"\"\"\n    tscv = TimeSeriesSplit(n_splits=10)\n    train_sizes_manual = []\n    test_sizes_manual = []\n    train_scores_manual = []\n    test_scores_manual = []\n    \n    y_actuals_raw = []\n    y_predicteds_raw = []\n    \n    # Manually .fit() and .evaluate() data via TSCV (as learning_curve() does not seem to work with TSCV, e.g. train_sizes wrong)\n    for train_index, test_index in tscv.split(X):\n        # 1. Define indizes for training and testing\n        first_train_index = 0\n        last_train_index = train_index[-1]\n        first_test_index = test_index[0]\n        last_test_index = test_index[-1]\n        if verbose is True:\n            print(\"Train on indices=[\" + str(first_train_index) + \", \" + str(last_train_index) + \n                  \"],test on indices=[\" + str(first_test_index) + \", \" + str(last_test_index) + \"], \" + \n                  \"i.e. train_size=\", len(train_index), \", test_size=\", len(test_index))\n        train_sizes_manual.extend([len(train_index)])\n        test_sizes_manual.extend([len(test_index)])\n        \n        # 2. Fit classifier and measure accuracy\n        X_train = X[first_train_index:last_train_index]\n        X_test = X[first_test_index:last_test_index]\n        y_train = y[first_train_index:last_train_index]\n        y_test = y[first_test_index:last_test_index]\n        \n        if return_raw_results is True:\n            y_actual, y_predicted = calculate_metrics(clf, X_train, X_test, y_train, y_test, return_raw_results=True)\n            # 3a. Add raw values to return list\n            y_actuals_raw.extend(y_actual)\n            y_predicteds_raw.extend(y_predicted)\n        else:\n            train_score = calculate_metrics(clf, X_train, X_train, y_train, y_train)\n            test_score = calculate_metrics(clf, X_train, X_test, y_train, y_test)\n            # 3b. Add new scores to return list\n            train_scores_manual.extend([train_score])\n            test_scores_manual.extend([test_score])\n    \n    if verbose is True and return_raw_results is False:\n        print(\"train_sizes_manual=\" + str(train_sizes_manual) + \", test_sizes_manual: \" + str(test_sizes_manual))\n        print(\"train_scores_manual=\" + str([round(e, 2) for e in train_scores_manual]))\n        print(\"test_scores_manual=\" + str([round(e, 2) for e in test_scores_manual]))\n    \n    if return_raw_results is True:\n        if verbose is True:\n            print(\"apply_tscv() done.\")\n        return y_actuals_raw, y_predicteds_raw\n    else:\n        return train_sizes_manual, train_scores_manual, test_scores_manual",
      "execution_count": 117,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3.2 | Calculate metrics for given classifier's X-s and y-s"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def calculate_metrics(clf, X_train, X_test, y_train, y_test, verbose=VERBOSE, return_raw_results=False):\n    \"\"\"\n    Calculates accuracy, precision, recall and f-measure for given classifier for given training and test data.\n    Only accepts y-DataFrames with one single column/one single horizon (as only one class is predicted).\n    return_raw_results argument, if True, returns the raw TP/TN/FP/FN values, instead of aggregated metrics\n    \"\"\"\n    if not isinstance(y_train, pd.Series) or not isinstance(y_test, pd.Series):\n        print(\"y-DataFrames must have 1 column only.\")\n        return -1\n    \n    clf.fit(X_train, y_train)\n    y_actual = y_test\n    y_predicted = clf.predict(X_test)\n    \n    acc = metrics.accuracy_score(y_actual, y_predicted)\n    precision = metrics.precision_score(y_actual, y_predicted) if (1 in y_predicted and 1 in y_actual) else -1\n    recall = metrics.recall_score(y_actual, y_predicted) if (1 in y_predicted and 1 in y_actual) else -1\n    f_measure = metrics.f1_score(y_actual, y_predicted) if (precision > 0 or recall >0) else -1\n    \n    if verbose is True:\n        print(\"calculate_metrics() -> model=\" + str(type(clf)) + \", class=\" + y_train.name + \", acc=\" + str(round(acc, 2)) + \n              \"prec=\" + str(precision) + \", recall=\" + str(precision) + \", f_score=\" + str(f_measure))\n    \n    if return_raw_results is True:\n        return y_actual, y_predicted\n    else:\n        return acc # TBD: return other metrics as well",
      "execution_count": 118,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 4 | Putting it all together (all above methods are called here in one single place)\n- Prepare, classify and evaluate datasets"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4.1 | Summarizing function for loading & extracting vs not data & splitting for train vs test"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def generate_train_test_data(filename=MSFT_DATA, extract_features=True, horizon_index=2, train_size=0.7, verbose=VERBOSE):\n    \"\"\"\n    Serves as a one-stop-shop function for data loading incl. preparation so that classifier only relies on this single fucntion (and not many single functions) \n    \"\"\"\n    # 1. Load data from .CSV (1.1)\n    df = load_OHLC_data(filename)\n    stock_ticker = df[\"Name\"][0]\n    \n    if verbose is True:\n        print(\"generate_train_test_data() for \" + str(stock_ticker))\n    \n    # 2. Extract features if applicable (1.2)\n    if extract_features is True:\n        df = extract_OHLC_features(df)\n    \n    # Detect anomalies (1.3) skipped\n    # 3. Define classes (1.4)\n    df = define_classes(df)\n    \n    # Check class balance (1.5) skipped\n    # 4. Split data into training and testing samples if applicable (or get 100% as training data to later apply CV)\n    X_train, X_test, y_train, y_test = train_test_split_data(df, train_size=train_size)\n    \n    # 5. Return one single class series, depending on the horizon_index provided\n    y_train = y_train[y_train.columns[horizon_index]]\n    y_test = y_test[y_test.columns[horizon_index]]\n    \n    return stock_ticker, X_train, X_test, y_train, y_test",
      "execution_count": 119,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(extract_features=False)\n# print(X_train.columns)\n# print(y_train.name)\n# stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(extract_features=True)\n# print(X_train.columns)\n# print(y_train.name)",
      "execution_count": 120,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### TBD: Compare INITIAL DF (call fucntion) with EXTRACTED DF (cal lfunction) to see if engineering any good"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4.3 | Test master function\n- Varying 4-5 dimensions simultaneously too complex, hence all but classifier is fixed in the master function\n- TBD: Toggle Hyperparameter Tuning somewhere\n- TBD: Correct testing for 0 values at the end, e.g. 365 horizon return in last week's data is always 0!! Must be accounted for"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# TIME_HORIZONS = [1, 5, 10, 20, 65, 250] <- use index from 0 (1 trading day) to 5 (250 trading days) to determine time horizon\ndef master_function(time_horizon=2):\n    # Create classifiers that are to be evaluated\n    clf1 = DummyClassifier(random_state=42)\n    clf2 = DecisionTreeClassifier(random_state=42)\n    clf3 = RandomForestClassifier(n_estimators=10, random_state=42)\n    clfs = [clf1, clf2, clf3]\n    \n    # Iterate over models & datasets to evaluate classifiers on each dataset\n    for clf in clfs:\n        cum_acc = 0\n        for dataset_path in TECH_GROUP:\n            # Load data and evaluate all models on it\n            evaluate_models(dataset=dataset_path, extract_features=False, time_horizon=time_horizon)\n            cum_acc = cum_acc + evaluate_models(dataset=dataset_path, extract_features=True, time_horizon=time_horizon)\n        clf_avg_acc = cum_acc/len(TECH_GROUP)\n        print(\"avg acc for \" + str(type(clf)) + \" is \" + str(round(clf_avg_acc, 2)))",
      "execution_count": 121,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# master_function()",
      "execution_count": 122,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 5 | Visualization\n- Plot learning curves"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5.1 | Plot acuracy curve on train vs test data\n- E.g. for different max_depth-s of decision tree\n- Measure accuracy by TimeSeriesSplit"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def plot_tscv_curve(clf, title, X, y, verbose=VERBOSE, save_fig=SAVE_FIG):\n    \"\"\"\n    Plots the accuracies on training and testing set for given classifier using Time Series Cross Validation\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    plt.ylim(0.00, 1.05)\n    \n    # Apply Time Series CV to given data\n    train_sizes_manual, train_scores_manual, test_scores_manual = apply_tscv(clf, X, y, verbose)\n    \n    # Plot data points for training and testing\n    plt.plot(train_sizes_manual, train_scores_manual, 'o-', color=\"r\", label=\"Training\")\n    plt.plot(train_sizes_manual, test_scores_manual, 'o-', color=\"g\", label=\"Test\")\n    mean_test_acc = [np.mean(test_scores_manual)]*len(test_scores_manual)\n    plt.plot(train_sizes_manual, mean_test_acc, '--', color=\"g\", label=\"Mean\")\n    plt.text(0.5, 0.01, \"Mean=\" + str(round(np.mean(test_scores_manual), 3)), size=\"15\", weight=\"bold\", \n             horizontalalignment=\"center\", verticalalignment=\"bottom\", transform=ax.transAxes)\n    \n    # Labeling\n    plt.xlabel(\"Anzahl Trainingsinstanzen\")\n    plt.ylabel(\"Treffergenauigkeit\")\n    plt.title(title)\n    plt.grid()\n    plt.legend(loc=4)\n    \n    if save_fig is True:\n        plt.savefig(\"./Plots/Performance-Curves/Plot-\" + title.replace(\" \", \"\") + \".jpeg\")\n    \n    # Return results for plotting results in master diagram with other clf's results\n    return train_sizes_manual, train_scores_manual, test_scores_manual",
      "execution_count": 265,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5.2 | Plot confusion matrix"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def plot_confusion_matrix(stock_ticker, horizon_index, y_actual, y_predicted, verbose=VERBOSE, save_fig=SAVE_FIG):\n    \"\"\"\n    Plots confusion matrix and returns precision, recall and f-measure\n    \"\"\"\n    # 1. Calculate metrics\n    precision = metrics.precision_score(y_actual, y_predicted) if (1 in y_predicted and 1 in y_actual) else -1\n    recall = metrics.recall_score(y_actual, y_predicted) if (1 in y_predicted and 1 in y_actual) else -1\n    f_measure = metrics.f1_score(y_actual, y_predicted) if (precision > 0 or recall >0) else -1\n    \n    if verbose is True:\n        print(\"plot_confusion_matrix() -> Result on stock=\" + str(stock_ticker) + \" is precision=\" \n              + str(round(precision, 3)) + \", recall=\" + str(round(recall, 3)) + \", f_measure=\" + str(round(f_measure, 3)))\n    if save_fig is True:\n        # 2. Build and plot confusion matrix via Seaborn\n        confusion_matrix = metrics.confusion_matrix(y_actual, y_predicted)\n        fig, ax = plt.subplots()\n        sns_ax = sns.heatmap(confusion_matrix, annot=True, annot_kws={'size':15}, fmt='g', cmap=plt.cm.Blues, cbar=False, square=True)\n        sns_ax.invert_yaxis()\n        sns_ax.invert_xaxis()\n        ax.set(title=\"Dummy Classifier, \" + str(stock_ticker) + \", Horizont-Index=\" + str(horizon_index), ylabel=\"Korrekte Klasse\", xlabel=\"Vorhergesagte Klasse\")\n        if stock_ticker == \"Tech-Group-AVG\": # ONLY FOR NON-EXTRACTEDS TEST\n            plt.savefig(\"./Plots/Confusion-Matrices-NoExtracteds/ConfusionMatrix-Dummy-HorizonIndex\" + str(horizon_index) + \"-\" + str(stock_ticker) + \".jpeg\")\n        plt.close()\n    return precision, recall, f_measure",
      "execution_count": 280,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 6 | Final Evaluations"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 6.1 | Confusion matrixes on TSCV folds per classifier and per stock"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_tscv_confusion_matrices(clf, verbose=VERBOSE, save_fig=SAVE_FIG):\n    \"\"\"\n    Calculates confusion matrix for each stock (n=11) and for each horizon (n=6) for a total of 66 combinations\n    \"\"\"\n    # 0. Store results for averaging across datasets\n    y_act_TechGroup = [[] for h in range(0, len(TIME_HORIZONS))]\n    y_pred_TechGroup = [[] for h in range(0, len(TIME_HORIZONS))]\n    stock_ticker = None\n    \n    # 1. Load and loop over stock datasets\n    for stock in TECH_GROUP:\n        print(\"get_tscv_confusion_matrices() -> Stock=\" + str(stock))\n        # 2. Loop over prediction horizons: 1, 5, 10, 20, 65, 250 trading (!) days\n        for horizon in  range(0, len(TIME_HORIZONS)):\n            # 3. Load data for stock-horizon combination. Train_size=100% because train-test splits will be done by TSCV function\n            stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(filename=stock, extract_features=False, horizon_index=horizon, train_size=1)\n            # 2. Get TSCV predictions for confusion matrix and save for later average across all stocks\n            y_act, y_pred = apply_tscv(clf, X_train, y_train, return_raw_results=True)\n            y_act_TechGroup[horizon].extend(y_act)\n            y_pred_TechGroup[horizon].extend(y_pred)\n            # 3. Create confusion matrix and save figures if applicable\n            precision, recall, f_measure = plot_confusion_matrix(stock_ticker, horizon, y_act, y_pred, verbose=True, save_fig=True)\n        \n    # 4. Average for each horizon across datasets\n    print(\"get_tscv_confusion_matrices() -> Stock=Tech Group Average\")\n    for horizon in  range(0, len(TIME_HORIZONS)):\n        precision, recall, f_measure = plot_confusion_matrix(\"Tech-Group-AVG\", horizon, y_act_TechGroup[horizon], y_pred_TechGroup[horizon], verbose=True, save_fig=True)",
      "execution_count": 278,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# Throw Dummy, DT, RF into get_tscv_confusion_matrices()\ndummy = DummyClassifier(random_state=RANDOM_SEED)\n# dt = DecisionTreeClassifier(random_state=RANDOM_SEED)\n# rf = RandomForestClassifier(random_state=RANDOM_SEED)\nget_tscv_confusion_matrices(dummy)",
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": "get_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_AAPL_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.509, recall=0.537, f_measure=0.522\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.541, recall=0.565, f_measure=0.553\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.583, recall=0.583, f_measure=0.583\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.612, recall=0.636, f_measure=0.624\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.693, recall=0.745, f_measure=0.718\nplot_confusion_matrix() -> Result on stock=AAPL is precision=0.601, recall=0.88, f_measure=0.714\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_AMZN_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.521, recall=0.559, f_measure=0.539\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.548, recall=0.558, f_measure=0.553\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.606, recall=0.629, f_measure=0.617\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.66, recall=0.658, f_measure=0.659\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.663, recall=0.733, f_measure=0.696\nplot_confusion_matrix() -> Result on stock=AMZN is precision=0.704, recall=0.862, f_measure=0.775\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_CSCO_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.529, recall=0.481, f_measure=0.504\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.574, recall=0.614, f_measure=0.593\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.565, recall=0.602, f_measure=0.583\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.551, recall=0.603, f_measure=0.576\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.597, recall=0.654, f_measure=0.624\nplot_confusion_matrix() -> Result on stock=CSCO is precision=0.667, recall=0.85, f_measure=0.748\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_GE_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=GE is precision=0.456, recall=0.524, f_measure=0.488\nplot_confusion_matrix() -> Result on stock=GE is precision=0.488, recall=0.529, f_measure=0.508\nplot_confusion_matrix() -> Result on stock=GE is precision=0.438, recall=0.542, f_measure=0.484\nplot_confusion_matrix() -> Result on stock=GE is precision=0.456, recall=0.593, f_measure=0.516\nplot_confusion_matrix() -> Result on stock=GE is precision=0.422, recall=0.655, f_measure=0.513\nplot_confusion_matrix() -> Result on stock=GE is precision=0.445, recall=0.772, f_measure=0.564\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_GOOGL_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.506, recall=0.53, f_measure=0.518\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.543, recall=0.578, f_measure=0.56\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.579, recall=0.618, f_measure=0.598\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.6, recall=0.625, f_measure=0.612\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.644, recall=0.725, f_measure=0.682\nplot_confusion_matrix() -> Result on stock=GOOGL is precision=0.667, recall=0.841, f_measure=0.744\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_HP_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=HP is precision=0.488, recall=0.545, f_measure=0.515\nplot_confusion_matrix() -> Result on stock=HP is precision=0.495, recall=0.552, f_measure=0.522\nplot_confusion_matrix() -> Result on stock=HP is precision=0.496, recall=0.577, f_measure=0.533\nplot_confusion_matrix() -> Result on stock=HP is precision=0.499, recall=0.583, f_measure=0.537\nplot_confusion_matrix() -> Result on stock=HP is precision=0.514, recall=0.691, f_measure=0.59\nplot_confusion_matrix() -> Result on stock=HP is precision=0.28, recall=0.543, f_measure=0.37\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_IBM_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.518, recall=0.502, f_measure=0.51\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.466, recall=0.5, f_measure=0.483\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.481, recall=0.416, f_measure=0.446\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.459, recall=0.374, f_measure=0.413\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.47, recall=0.343, f_measure=0.396\nplot_confusion_matrix() -> Result on stock=IBM is precision=0.188, recall=0.126, f_measure=0.151\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_INTC_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.502, recall=0.55, f_measure=0.525\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.523, recall=0.58, f_measure=0.55\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.548, recall=0.584, f_measure=0.565\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.566, recall=0.625, f_measure=0.594\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.576, recall=0.669, f_measure=0.619\nplot_confusion_matrix() -> Result on stock=INTC is precision=0.588, recall=0.843, f_measure=0.693\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_MSFT_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.499, recall=0.546, f_measure=0.522\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.579, recall=0.617, f_measure=0.598\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.598, recall=0.657, f_measure=0.626\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.647, recall=0.66, f_measure=0.654\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.741, recall=0.717, f_measure=0.729\nplot_confusion_matrix() -> Result on stock=MSFT is precision=0.759, recall=0.967, f_measure=0.85\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_WU_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=WU is precision=0.489, recall=0.561, f_measure=0.523\nplot_confusion_matrix() -> Result on stock=WU is precision=0.531, recall=0.615, f_measure=0.57\nplot_confusion_matrix() -> Result on stock=WU is precision=0.517, recall=0.619, f_measure=0.564\nplot_confusion_matrix() -> Result on stock=WU is precision=0.497, recall=0.651, f_measure=0.564\nplot_confusion_matrix() -> Result on stock=WU is precision=0.448, recall=0.618, f_measure=0.52\nplot_confusion_matrix() -> Result on stock=WU is precision=0.461, recall=0.687, f_measure=0.552\nget_tscv_confusion_matrices() -> Stock=Datasets/Kaggle_SnP500_XRX_2013-2018.csv\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.497, recall=0.572, f_measure=0.532\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.528, recall=0.617, f_measure=0.569\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.537, recall=0.656, f_measure=0.59\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.539, recall=0.7, f_measure=0.609\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.454, recall=0.756, f_measure=0.567\nplot_confusion_matrix() -> Result on stock=XRX is precision=0.306, recall=0.894, f_measure=0.455\nget_tscv_confusion_matrices() -> Stock=Tech Group Average\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.501, recall=0.537, f_measure=0.518\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.53, recall=0.577, f_measure=0.552\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.544, recall=0.593, f_measure=0.567\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.559, recall=0.615, f_measure=0.586\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.574, recall=0.672, f_measure=0.62\nplot_confusion_matrix() -> Result on stock=Tech-Group-AVG is precision=0.566, recall=0.804, f_measure=0.664\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# --------------------------------------------Ignore below------------------------------------------------"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.1.1 | Decision tree hyperparameter variation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def evaluate_dt(filename=AAPL_DATA, extract_features=True, horizon_index=2):\n    # Load data\n    stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(filename, extract_features, horizon_index, train_size=1)\n\n    # Generate classifier\n    clf = DecisionTreeClassifier(random_state=RANDOM_SEED)\n\n    # Gather all plotted series to create master plot\n    plotted_Xs = []\n    plotted_ys_train = []\n    plotted_ys_test = []\n\n    # Evaluate classifier for different values of selected hyperparameter\n    for i in [1, 3, 5, 6, 7, 9, 11, None]:\n        clf.set_params(max_depth=i)\n        X_res, y_train_res, y_test_res = plot_tscv_curve(clf, \"Decision Tree Treffergenauigkeiten AAPL (MAX_DEPTH=\" + str(i) + \")\", X_train, y_train, save_fig=SAVE_FIG)\n        print(\"Mean test accuracy for MAX_DEPTH=\" + str(i) + \": \" + str(round(np.mean(y_test_res), 3)))\n        \n        # Throw best params from 2.2 (Hyperparameter tuning) in and see if same result\n        if i == 7:\n            print(\"i is 7, so here we try the GRID_SEARCHED-best params: 'max_depth': 29, 'max_features': 29, 'min_samples_leaf': 1, 'min_samples_split': 15}, achieved 58.3% acc above\")\n            clf_best_params = DecisionTreeClassifier(random_state=RANDOM_SEED, max_depth=29, max_features=29, min_samples_leaf=1, min_samples_split=15)\n            X_res, y_train_res, y_test_res = plot_tscv_curve(clf_best_params, \"Decision Tree Treffergenauigkeiten AAPL (BEST_PARAMS)\", X_train, y_train, save_fig=SAVE_FIG)\n            print(\"Best-params DT achievend ACC=\" + str(i) + \": \" + str(round(np.mean(y_test_res), 3)))\n        \n        # TBD: Use all results to make master plot\n        plotted_Xs.extend([X_res])\n        plotted_ys_train.extend([y_train_res])\n        plotted_ys_test.extend([y_test_res])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# evaluate_dt(filename=AAPL_DATA, extract_features=True, horizon_index=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.1.2 | Classifier horizon variation (averaged aross TECH_GROUP)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def eval_avg_across_tech(clf):\n    \"\"\"\n    Evaluates accuracy of given classifier for each time horizon (accuracy average cross TECH_GROUP)\n    \"\"\"\n    accs_horizons = []\n    for horizon in range(0, 6):\n        accs_datasets = []\n        for file in TECH_GROUP:\n            # 1. Load data\n            stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(file, horizon_index=horizon, train_size=1)\n            \n            # 2. Evaluate classifier\n            train_sizes_manual, train_scores_manual, test_scores_manual = apply_tscv(clf, X_train, y_train)\n#             print(\"ACC for horizon=\" + str(horizon) + \" & file=\" + str(file) + \" is \" + str(np.mean(test_scores_manual)))\n            accs_datasets.extend([np.mean(test_scores_manual)])\n        print(\"ACC for horizon=\" + str(horizon) + \" is \" + str(np.mean(accs_datasets)))\n        accs_horizons.extend([np.mean(accs_datasets)])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# clf = DecisionTreeClassifier(random_state=RANDOM_SEED)\n# eval_avg_across_tech(clf)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# clf = RandomForestClassifier(random_state=RANDOM_SEED)\n# eval_avg_across_tech(clf)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6.2 | Random forest hyperparameter variation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def evaluate_rf(filename=AAPL_DATA, extract_features=True, horizon_index=2):\n    # Load data\n    stock_ticker, X_train, X_test, y_train, y_test = generate_train_test_data(filename, extract_features, horizon_index, train_size=1)\n\n    # Generate classifier\n    clf = RandomForestClassifier(n_estimators = 1, random_state=RANDOM_SEED)\n\n    # Evaluate classifier for different values of selected hyperparameter\n    for i in [1, 5, 10, 50, 100]:\n        clf.set_params(n_estimators=i)\n        X_res, y_train_res, y_test_res = plot_tscv_curve(clf, \"Random Forest Treffergenauigkeiten AAPL (N_ESTIMATORS=\" + str(i) + \")\", X_train, y_train, save_fig=SAVE_FIG)\n        print(\"Mean test accuracy for N_ESTIMATORS=\" + str(i) + \": \" + str(round(np.mean(y_test_res), 3)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# evaluate_rf(filename=MSFT_DATA, extract_features=True, horizon_index=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Comparison table: Model-Extractets-Horizon"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "- DT auf AAPL: Bei Variierung von MAX_DEPTH ist MAX(EXTRACTEDS)=56.2 , MAX(NO EXTRACTEDS)=53.3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}